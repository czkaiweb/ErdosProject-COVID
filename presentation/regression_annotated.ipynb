{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8a3d0b1-d90f-4088-8bb4-6f8ed08b9430",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages we'll use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate\n",
    "from sklearn.base import clone\n",
    "import datetime as dt\n",
    "\n",
    "_default_date_format = \"%Y-%m-%d\"\n",
    "\n",
    "\n",
    "#define a function that takes a date and the format the date is in as inputs and changes that to an ordinal\n",
    "#strptime: takes 2 inputs: (string that is a date, format that the date is in)\n",
    "def date_to_int(date_string: str, form: str=_default_date_format) -> int:\n",
    "    \"\"\"Return date date_string in format form as an integer\"\"\"\n",
    "    return dt.datetime.strptime(date_string, form).toordinal()\n",
    "\n",
    "\n",
    "#function that's the inverse of the last function\n",
    "def int_to_date(ordinal: int, form: str=_default_date_format) -> str:\n",
    "    \"\"\"Return the day number ordinal to as a string, formatted with form\"\"\"\n",
    "    return dt.datetime.fromordinal(ordinal).strftime(form)\n",
    "\n",
    "\n",
    "#adding lag: shifting features by n days. E.g. if n=14, then for a particular day we could be looking at\n",
    "#the number of new covid cases 14 days ago, or the number of covid beds used 14 days ago\n",
    "def add_lag(df, feature_dict):\n",
    "    \"\"\"Return a dataframe obtained from df by adding lag\n",
    "    feature called featurename-n for each featurename in feature_dict\n",
    "    and each n in feature_dict[featurename]\"\"\"\n",
    "    series_list = []\n",
    "    for feature in feature_dict.keys():\n",
    "        for n in feature_dict[feature]:\n",
    "            if n != 0:\n",
    "                series = df[feature].shift(n).copy().rename(f\"{feature}-{n}\")\n",
    "                series_list.append(series) \n",
    "    untrimmed = pd.concat([df[feature_dict.keys()]] + series_list, axis=1).copy()\n",
    "    #adding the series to main data frame\n",
    "    return untrimmed.iloc[max(np.max(feature_dict[feature]) \\\n",
    "                                  for feature in feature_dict \\\n",
    "                                 if len(feature_dict[feature]) > 0):]\n",
    "    #getting rid of data that's too early--doesn't have enough previous days\n",
    "\n",
    "    \n",
    "#reading the spreadsheet. Making a dictionary where the keys are each state\n",
    "#the values are the data frame gotten from the csv for that state\n",
    "def load_states():\n",
    "    \"\"\"Read state covid data\"\"\"\n",
    "    covid_all_states = {}\n",
    "    state_list = []\n",
    "    state_dir = join(\"..\", \"data\", \"input\", \"simple_states\")\n",
    "    for filename in listdir(state_dir):\n",
    "        if filename[-4:] == \".csv\":\n",
    "            state = filename[:-4]\n",
    "            covid_all_states[state] = pd.read_csv(join(state_dir, filename))\n",
    "            state_list.append(state)\n",
    "    return covid_all_states, state_list\n",
    "\n",
    "\n",
    "    \n",
    "class FuturePrediction:\n",
    "    \"\"\"Time series cross-validator\n",
    "    \n",
    "            Provides train/test indices to split data in train/test sets.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_length : int\n",
    "        Length of training period.\n",
    "    \n",
    "    future_time : int\n",
    "        Number of time periods in the future we want to predict\n",
    "        \n",
    "    interval : int, default=1\n",
    "        One out of this many time periods is chosen to validate\n",
    "    \n",
    "    randomize : bool, default=False\n",
    "        Randomize which days are chosen to validate\n",
    "    \"\"\"\n",
    "    def __init__(self, train_length, future_interval,\n",
    "                 interval=1, randomize=False):\n",
    "        self.train_length = train_length\n",
    "        self.future_interval = future_interval\n",
    "        self.interval = interval\n",
    "        self.randomize = randomize\n",
    "    #init method: like k-fold. but we're defining it ourselves\n",
    "    #when you call a method of a class, the object of the class itself is already passed as a first argument\n",
    "        \n",
    "    def split(self, df):\n",
    "        length = len(df)\n",
    "        index = 0\n",
    "        max_index = length - self.train_length - self.future_interval\n",
    "        while index < max_index:\n",
    "            yield np.arange(index, index+self.train_length), \\\n",
    "                    np.array([index+self.train_length+self.future_interval-1])\n",
    "            #yield is a generator (i.e. a thing you can loop over). every time you see a yield statement, add this pair\n",
    "            #of things to the list. return the list at the end. difference between yield and list: yield returns things one\n",
    "            #at a time instead of all at once\n",
    "            if self.randomize:\n",
    "                index = index+np.randint(1, 2*self.interval)\n",
    "            #if we specify self.randomize to be True, it increments by that value. otherwise, it just increments\n",
    "            #by self.interval\n",
    "            else:\n",
    "                index = index+self.interval\n",
    "                \n",
    "                \n",
    "#plot the actual number of hospital beds used against the number predicted based on our model and also\n",
    "#the baseline prediction: predicting that the number of beds used in n days will be exactly the same as now\n",
    "def plot_predictions(reg, df, train_length, future_interval, features):\n",
    "    actuals, baselines, predicteds = list(), list(), list()\n",
    "    cv = FuturePrediction(train_length, future_interval)\n",
    "    for train_index, test_index in cv.split(df):\n",
    "        train, test = df.iloc[train_index], df.iloc[test_index]\n",
    "        actual = test.beds.iloc[0]\n",
    "        reg_copy = clone(reg)\n",
    "        reg_copy.fit(train[features], train[\"beds\"])\n",
    "        predicted = reg_copy.predict(test[features])[0]\n",
    "        target = f\"beds-{future_interval}\"\n",
    "        baseline = test[target].iloc[0]\n",
    "        actuals.append(actual)\n",
    "        baselines.append(baseline)\n",
    "        predicteds.append(predicted)\n",
    "    \n",
    "    plt.plot(actuals, label=\"actual\")\n",
    "    plt.plot(baselines, label=\"baseline\")\n",
    "    plt.plot(predicteds, label=\"predicted\")\n",
    "    start_date = df.date.iloc[train_length+future_interval-1]\n",
    "    end_date = df.date.iloc[-1]\n",
    "    plt.xticks([0,len(actuals)-1], [start_date, end_date])\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Covid beds in use\")\n",
    "    plt.legend()\n",
    "    return None\n",
    "\n",
    "def validate(covid_state, regressor, train_length,\n",
    "             future_interval, max_lag, interval, param_grid,\n",
    "            plot=False):\n",
    "    \"\"\" Performs state-by-state optimization of hyperparameters\n",
    "    \n",
    "        Parameters:\n",
    "        covid_state: dictionary\n",
    "            Dictionary of data frames with state data\n",
    "            \n",
    "        regreessor: regression object\n",
    "        train_length: integer\n",
    "            Number of training data points to fit\n",
    "        future_interval: integer\n",
    "            Number of days in the future we want to predict\n",
    "        max_lag: integer\n",
    "            Max number of days worth of data to use in each data point\n",
    "        interval: integer\n",
    "            Space between testing days for GridSearchCV\n",
    "        param_grid: dictionary\n",
    "            Hyperparameter values to check (passed to GridSearchCV)\n",
    "    \"\"\"\n",
    "    cv = FuturePrediction(train_length, future_interval, interval)\n",
    "    cv_test = FuturePrediction(train_length, future_interval)\n",
    "    ratios = []\n",
    "    for state in covid_state:\n",
    "        df = add_lag(covid_state[state],\n",
    "                    {\"beds\": range(future_interval, future_interval+max_lag),\n",
    "                    \"cases_7day\": range(future_interval, future_interval+max_lag),\n",
    "                    \"vaccines\": [future_interval],\n",
    "                    \"date\":[],\n",
    "                    \"day_number\":[]})\n",
    "        train = df.loc[(df.day_number >= date_to_int(\"2021-01-01\")) &\n",
    "                      (df.day_number <= date_to_int(\"2021-07-01\"))].copy()\n",
    "        test = df.loc[(df.day_number > date_to_int(\"2021-07-01\")) &\n",
    "                      (df.day_number < date_to_int(\"2021-09-01\"))].copy()\n",
    "\n",
    "        gs = GridSearchCV(regressor,\n",
    "                    param_grid=param_grid,\n",
    "                    scoring=\"neg_mean_squared_error\",\n",
    "                    cv=cv.split(train),\n",
    "                    n_jobs=-1)\n",
    "        #first argument: regression object. it gets cloned many times with different values of hyperparameters.\n",
    "        #set hyperparameters, fit it, compare with other values of hyperparameters\n",
    "        #param_grid argument: dictionary. each key of the dictionary is the name of a hyperparameter. value of dictionary at that key\n",
    "        #is the list of possible values for that hyperparameter\n",
    "        \n",
    "        features = [f\"beds-{k}\" for k in range(future_interval, future_interval+max_lag)] + \\\n",
    "                    [f\"cases_7day-{k}\" for k in range(future_interval, future_interval+max_lag)] + \\\n",
    "                    [f\"vaccines-{future_interval}\"]\n",
    "        gs.fit(train[features], train[\"beds\"])\n",
    "        reg = gs.best_estimator_\n",
    "        #best_estimator_: one of the attributes gridsearch has built in. \n",
    "        q = cross_validate(reg, test[features],\n",
    "                       test[\"beds\"],\n",
    "                       scoring=\"neg_mean_squared_error\",\n",
    "                       cv=cv_test.split(test))\n",
    "        regression_mse = -q[\"test_score\"].mean()\n",
    "        baseline_mse = ((test[f\"beds-{future_interval}\"].iloc[train_length+future_interval-1:]-\\\n",
    "                         test[\"beds\"].iloc[train_length+future_interval-1:])**2).mean()\n",
    "        ratio = regression_mse/baseline_mse\n",
    "        print(state, ratio)\n",
    "        #print(gs.best_params_)\n",
    "        ratios.append(ratio)\n",
    "        if plot:\n",
    "            plot_predictions(reg, test, train_length, future_interval, features)\n",
    "            plt.title(f\"{state} holdout data\")\n",
    "            plt.show()\n",
    "    return np.mean(ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e3049df-8e71-4131-bdba-e53ff482a43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KFold:\n",
    "    def __init__(self, number_of_pieces, randomize=False):\n",
    "        self.number_of_pieces=number_of_pieces\n",
    "        #on the right of = sign, has to match: number_of_pieces. On the left, we could name it something else.\n",
    "        #self.number=number_of_pieces would also work\n",
    "        #this stores self.number_of_pieces as part of k-fold class\n",
    "        #we can still access it in another method\n",
    "        self.randomize=randomize\n",
    "        print('abcd', self.number_of_pieces)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbaaf084-b8ad-4d08-ac70-8c42797cd8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcd 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold=KFold(5)\n",
    "kfold.number_of_pieces\n",
    "kfold.randomize"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
